# LoLShorts Production Roadmap
**Target**: 100% Feature-Complete, Production-Ready Application
**Current Status**: Phase 0 Complete (20% of total project)
**Timeline**: 22 weeks (2-person team) | 35 weeks (solo)
**Last Updated**: 2025-11-04

---

## üéØ Executive Summary

### Current Status
- **Phase 0 (Core Recording)**: ‚úÖ **100% COMPLETE**
  - FFmpeg CLI-based circular buffer recording
  - 60-second replay window (6 segments √ó 10s)
  - Hardware-accelerated H.265 encoding (NVENC/QSV/AMF)
  - Event detection stub (LCU + Live Client Data API)
  - Thread-safe architecture validated
  - 3 compiler warnings, 0 errors

- **Overall Production Readiness**: **20%** (1 of 5 waves complete)

### What Works Right Now
‚úÖ Windows screen recording with hardware encoding
‚úÖ Circular buffer (automatic segment rotation)
‚úÖ Basic Tauri commands (start/stop/status)
‚úÖ React dashboard with recording controls
‚úÖ SQLite database schema
‚úÖ Project structure and architecture

### What Needs Implementation
‚ùå Supabase authentication
‚ùå License tier system (FREE vs PRO)
‚ùå Video processing (extraction, composition, export)
‚ùå Professional video editor UI
‚ùå AI-powered auto-editing
‚ùå Deployment infrastructure

### Timeline to 100% Completion
- **2-Person Team**: 22 weeks (recommended)
- **Solo Development**: 35 weeks
- **4-Person Team**: 14 weeks (if budget allows)

### Investment Required
- **Total Cost**: $61,100 (includes team salaries, tools, infrastructure)
- **Monthly Ongoing**: $1,151/month (hosting, monitoring, domains)
- **Break-Even**: 150 PRO users @ $9.99/month

---

## üìä Wave Overview

| Wave | Focus | Duration (2p) | Duration (solo) | Status |
|------|-------|---------------|-----------------|--------|
| **Wave 1** | LCU Integration & Authentication | 5 weeks | 8 weeks | üìÖ Planned |
| **Wave 2** | Video Processing Pipeline | 6 weeks | 10 weeks | üìÖ Planned |
| **Wave 3** | Auto-Composition & AI | 5 weeks | 8 weeks | üìÖ Planned |
| **Wave 4** | Professional Video Editor UI | 4 weeks | 6 weeks | üìÖ Planned |
| **Wave 5** | Deployment & Distribution | 2 weeks | 3 weeks | üìÖ Planned |
| **Total** | **Full Production System** | **22 weeks** | **35 weeks** | **20% Complete** |

---

## üöÄ Wave 1: LCU Integration & Authentication (5 weeks)

### Overview
**Goal**: Connect to League Client, authenticate users, manage licenses, capture screenshots, detect high-priority events

**Critical Dependencies**:
- Supabase account setup
- Windows Credential Manager access
- LCU API documentation
- Live Client Data API testing

### 1.1 Supabase Authentication (Week 1-2)

#### Backend Implementation
**File**: `src-tauri/src/auth/supabase.rs`

```rust
use reqwest::Client;
use serde::{Deserialize, Serialize};
use anyhow::Result;

#[derive(Debug, Clone)]
pub struct SupabaseClient {
    client: Client,
    project_url: String,
    anon_key: String,
}

#[derive(Debug, Serialize)]
struct SignUpRequest {
    email: String,
    password: String,
}

#[derive(Debug, Deserialize)]
pub struct User {
    pub id: String,
    pub email: String,
    pub created_at: String,
}

#[derive(Debug, Deserialize)]
pub struct Session {
    pub access_token: String,
    pub refresh_token: String,
    pub expires_in: i64,
    pub user: User,
}

impl SupabaseClient {
    pub fn new(project_url: String, anon_key: String) -> Self {
        Self {
            client: Client::new(),
            project_url,
            anon_key,
        }
    }

    pub async fn sign_up(&self, email: &str, password: &str) -> Result<Session> {
        let url = format!("{}/auth/v1/signup", self.project_url);

        let response = self.client
            .post(&url)
            .header("apikey", &self.anon_key)
            .json(&SignUpRequest {
                email: email.to_string(),
                password: password.to_string(),
            })
            .send()
            .await?;

        let session: Session = response.json().await?;
        Ok(session)
    }

    pub async fn sign_in(&self, email: &str, password: &str) -> Result<Session> {
        let url = format!("{}/auth/v1/token?grant_type=password", self.project_url);

        let response = self.client
            .post(&url)
            .header("apikey", &self.anon_key)
            .json(&SignUpRequest {
                email: email.to_string(),
                password: password.to_string(),
            })
            .send()
            .await?;

        let session: Session = response.json().await?;
        Ok(session)
    }

    pub async fn refresh_token(&self, refresh_token: &str) -> Result<Session> {
        let url = format!("{}/auth/v1/token?grant_type=refresh_token", self.project_url);

        let response = self.client
            .post(&url)
            .header("apikey", &self.anon_key)
            .json(&serde_json::json!({
                "refresh_token": refresh_token
            }))
            .send()
            .await?;

        let session: Session = response.json().await?;
        Ok(session)
    }

    pub async fn get_user(&self, access_token: &str) -> Result<User> {
        let url = format!("{}/auth/v1/user", self.project_url);

        let response = self.client
            .get(&url)
            .header("apikey", &self.anon_key)
            .header("Authorization", format!("Bearer {}", access_token))
            .send()
            .await?;

        let user: User = response.json().await?;
        Ok(user)
    }
}
```

**Tauri Commands**: `src-tauri/src/auth/commands.rs`

```rust
use tauri::State;
use crate::auth::supabase::{SupabaseClient, Session};

#[tauri::command]
pub async fn sign_up(
    supabase: State<'_, SupabaseClient>,
    email: String,
    password: String,
) -> Result<Session, String> {
    supabase.sign_up(&email, &password)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn sign_in(
    supabase: State<'_, SupabaseClient>,
    email: String,
    password: String,
) -> Result<Session, String> {
    supabase.sign_in(&email, &password)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
pub async fn refresh_session(
    supabase: State<'_, SupabaseClient>,
    refresh_token: String,
) -> Result<Session, String> {
    supabase.refresh_token(&refresh_token)
        .await
        .map_err(|e| e.to_string())
}
```

**Frontend Integration**: `src/stores/authStore.ts`

```typescript
import { create } from 'zustand';
import { invoke } from '@tauri-apps/api/tauri';

interface User {
  id: string;
  email: string;
  createdAt: string;
}

interface Session {
  accessToken: string;
  refreshToken: string;
  expiresIn: number;
  user: User;
}

interface AuthStore {
  session: Session | null;
  isAuthenticated: boolean;

  signUp: (email: string, password: string) => Promise<void>;
  signIn: (email: string, password: string) => Promise<void>;
  signOut: () => void;
  refreshSession: () => Promise<void>;
}

export const useAuthStore = create<AuthStore>((set, get) => ({
  session: null,
  isAuthenticated: false,

  signUp: async (email, password) => {
    const session = await invoke<Session>('sign_up', { email, password });

    // Store tokens in Windows Credential Manager
    await invoke('store_credentials', {
      accessToken: session.accessToken,
      refreshToken: session.refreshToken,
    });

    set({ session, isAuthenticated: true });
  },

  signIn: async (email, password) => {
    const session = await invoke<Session>('sign_in', { email, password });

    await invoke('store_credentials', {
      accessToken: session.accessToken,
      refreshToken: session.refreshToken,
    });

    set({ session, isAuthenticated: true });
  },

  signOut: () => {
    invoke('clear_credentials');
    set({ session: null, isAuthenticated: false });
  },

  refreshSession: async () => {
    const { session } = get();
    if (!session) return;

    const newSession = await invoke<Session>('refresh_session', {
      refreshToken: session.refreshToken,
    });

    await invoke('store_credentials', {
      accessToken: newSession.accessToken,
      refreshToken: newSession.refreshToken,
    });

    set({ session: newSession });
  },
}));
```

### 1.2 License Tier System (Week 2)

#### Database Schema
**File**: `src-tauri/migrations/003_licenses.sql`

```sql
CREATE TABLE licenses (
    user_id TEXT PRIMARY KEY,
    tier TEXT NOT NULL CHECK (tier IN ('FREE', 'PRO')),
    expires_at INTEGER,
    stripe_subscription_id TEXT,
    created_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX idx_licenses_tier ON licenses(tier);
CREATE INDEX idx_licenses_expires_at ON licenses(expires_at);
```

#### Backend Implementation
**File**: `src-tauri/src/feature_gate/mod.rs`

```rust
use sqlx::SqlitePool;
use anyhow::Result;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LicenseTier {
    FREE,
    PRO,
}

#[derive(Debug)]
pub struct License {
    pub user_id: String,
    pub tier: LicenseTier,
    pub expires_at: Option<i64>,
}

pub struct FeatureGate {
    db: SqlitePool,
}

impl FeatureGate {
    pub fn new(db: SqlitePool) -> Self {
        Self { db }
    }

    pub async fn get_license(&self, user_id: &str) -> Result<License> {
        let row = sqlx::query!(
            r#"
            SELECT user_id, tier, expires_at
            FROM licenses
            WHERE user_id = ?
            "#,
            user_id
        )
        .fetch_one(&self.db)
        .await?;

        let tier = match row.tier.as_str() {
            "PRO" => LicenseTier::PRO,
            _ => LicenseTier::FREE,
        };

        Ok(License {
            user_id: row.user_id,
            tier,
            expires_at: row.expires_at,
        })
    }

    pub async fn is_pro(&self, user_id: &str) -> Result<bool> {
        let license = self.get_license(user_id).await?;

        if license.tier != LicenseTier::PRO {
            return Ok(false);
        }

        // Check if license expired
        if let Some(expires_at) = license.expires_at {
            let now = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)?
                .as_secs() as i64;

            Ok(now < expires_at)
        } else {
            Ok(true)
        }
    }

    pub fn can_export_1080p(&self, tier: LicenseTier) -> bool {
        tier == LicenseTier::PRO
    }

    pub fn can_remove_watermark(&self, tier: LicenseTier) -> bool {
        tier == LicenseTier::PRO
    }

    pub fn can_use_ai_editing(&self, tier: LicenseTier) -> bool {
        tier == LicenseTier::PRO
    }

    pub fn max_clips_per_compilation(&self, tier: LicenseTier) -> usize {
        match tier {
            LicenseTier::FREE => 5,
            LicenseTier::PRO => 50,
        }
    }
}
```

### 1.3 Screenshot Capture (Week 3)

**File**: `src-tauri/src/recording/screenshot.rs`

```rust
use image::{ImageBuffer, Rgba};
use screenshots::Screen;
use anyhow::Result;
use std::path::PathBuf;

pub struct ScreenshotCapture {
    output_dir: PathBuf,
}

impl ScreenshotCapture {
    pub fn new(output_dir: PathBuf) -> Self {
        Self { output_dir }
    }

    pub async fn capture(&self, filename: &str) -> Result<PathBuf> {
        let screens = Screen::all()?;
        let primary = screens.first()
            .ok_or_else(|| anyhow::anyhow!("No screen found"))?;

        let image = primary.capture()?;

        let output_path = self.output_dir.join(filename);
        image.save(&output_path)?;

        Ok(output_path)
    }

    pub async fn capture_champion_select(&self, game_id: i64) -> Result<PathBuf> {
        let filename = format!("champion_select_{}.png", game_id);
        self.capture(&filename).await
    }

    pub async fn capture_game_start(&self, game_id: i64) -> Result<PathBuf> {
        let filename = format!("game_start_{}.png", game_id);
        self.capture(&filename).await
    }

    pub async fn capture_clip_thumbnail(&self, clip_id: i64, timestamp: f64) -> Result<PathBuf> {
        // This will be replaced by FFmpeg frame extraction in Wave 2
        let filename = format!("clip_thumb_{}_{}.png", clip_id, timestamp);
        self.capture(&filename).await
    }
}
```

### 1.4 Enhanced Event Detection (Week 4-5)

**File**: `src-tauri/src/recording/live_client.rs` (enhancement)

```rust
// Add to existing implementation

impl LiveClientMonitor {
    async fn detect_trigger(&self, event: &GameEvent, player_name: &str) -> Option<EventTrigger> {
        match event.event_name.as_str() {
            "ChampionKill" => {
                if let Some(killer) = &event.killer_name {
                    if killer == player_name {
                        // Check for multikill
                        let multikill = self.check_multikill(killer).await;

                        if multikill >= 5 {
                            Some(EventTrigger::Pentakill)
                        } else if multikill == 4 {
                            Some(EventTrigger::Quadrakill)
                        } else if multikill == 3 {
                            Some(EventTrigger::Triplekill)
                        } else if multikill == 2 {
                            Some(EventTrigger::Doublekill)
                        } else {
                            Some(EventTrigger::ChampionKill)
                        }
                    } else if event.victim_name.as_deref() == Some(player_name) {
                        // Player died - check for clutch play
                        self.detect_clutch_play(event).await
                    } else {
                        None
                    }
                } else {
                    None
                }
            }

            "DragonKill" => {
                if let Some(killer) = &event.killer_name {
                    if killer == player_name || event.assisters.contains(&player_name.to_string()) {
                        // Check dragon type for priority
                        let dragon_type = event.dragon_type.as_deref().unwrap_or("Unknown");
                        match dragon_type {
                            "Elder" => Some(EventTrigger::ElderDragon),
                            _ => Some(EventTrigger::Dragon),
                        }
                    } else {
                        None
                    }
                } else {
                    None
                }
            }

            "BaronKill" => {
                if let Some(killer) = &event.killer_name {
                    if killer == player_name || event.assisters.contains(&player_name.to_string()) {
                        Some(EventTrigger::Baron)
                    } else {
                        None
                    }
                } else {
                    None
                }
            }

            "TurretKilled" => Some(EventTrigger::TowerKill),
            "InhibKilled" => Some(EventTrigger::InhibitorKill),
            "Ace" => Some(EventTrigger::Ace),

            _ => None,
        }
    }

    async fn detect_clutch_play(&self, event: &GameEvent) -> Option<EventTrigger> {
        // TODO: Implement clutch play detection
        // Criteria:
        // - Player dies but gets 2+ kills before dying
        // - Player survives 1v2+ situation
        // - Player escapes with <10% HP
        None
    }

    async fn check_multikill(&self, killer: &str) -> u8 {
        let mut count = 1;
        let time_window = Duration::from_secs(10);

        let recent_kills = self.get_recent_kills(killer, time_window).await;
        count += recent_kills.len() as u8;

        count
    }
}
```

### Wave 1 Validation Checklist

‚úÖ **Authentication**:
- [ ] User can sign up with email/password
- [ ] User can sign in and receive JWT token
- [ ] Token refresh works automatically
- [ ] Credentials stored securely in Windows Credential Manager
- [ ] Session persists across app restarts

‚úÖ **License Management**:
- [ ] FREE tier user can record and export with watermark
- [ ] PRO tier user can export without watermark
- [ ] PRO tier user can export 1080p60
- [ ] License expiration detected correctly
- [ ] UI shows tier status and features

‚úÖ **Screenshot Capture**:
- [ ] Champion select screenshot captured
- [ ] Game start screenshot captured
- [ ] Thumbnails generated for clips

‚úÖ **Event Detection**:
- [ ] Pentakill detected and prioritized (5‚≠ê)
- [ ] Quadrakill detected (4‚≠ê)
- [ ] Baron/Elder Dragon detected (4‚≠ê)
- [ ] Triplekill detected (3‚≠ê)
- [ ] All events correctly associated with clips

---

## üé¨ Wave 2: Video Processing Pipeline (6 weeks)

### Overview
**Goal**: Extract clips from segments, generate thumbnails, compose multi-clip videos, create professional video editor backend

**Critical Dependencies**:
- FFmpeg 6.0+ installed
- `ffmpeg-sidecar` crate for process management
- Clip metadata in database
- Event-to-clip associations

### 2.1 FFmpeg Wrapper (Week 1)

**File**: `src-tauri/Cargo.toml` (add dependency)

```toml
[dependencies]
ffmpeg-sidecar = "1.1"
```

**File**: `src-tauri/src/video/ffmpeg_wrapper.rs`

```rust
use ffmpeg_sidecar::command::FfmpegCommand;
use ffmpeg_sidecar::event::{FfmpegEvent, LogLevel};
use anyhow::Result;
use std::path::{Path, PathBuf};
use tokio::sync::mpsc;

pub struct FFmpegWrapper {
    ffmpeg_path: Option<PathBuf>,
}

impl FFmpegWrapper {
    pub fn new() -> Self {
        Self {
            ffmpeg_path: None,
        }
    }

    pub fn with_path(path: PathBuf) -> Self {
        Self {
            ffmpeg_path: Some(path),
        }
    }

    pub async fn extract_segment(
        &self,
        input: &Path,
        output: &Path,
        start: f64,
        duration: f64,
        progress_tx: Option<mpsc::Sender<f64>>,
    ) -> Result<()> {
        let mut command = FfmpegCommand::new();

        if let Some(path) = &self.ffmpeg_path {
            command = command.path(path);
        }

        command
            .input(input)
            .args(&[
                "-ss", &start.to_string(),
                "-t", &duration.to_string(),
                "-c", "copy",  // Stream copy for speed
            ])
            .output(output)
            .spawn()?
            .iter()?
            .for_each(|event| {
                match event {
                    FfmpegEvent::Progress(p) => {
                        if let Some(tx) = &progress_tx {
                            let percent = (p.time.as_secs_f64() / duration) * 100.0;
                            tx.try_send(percent.min(100.0)).ok();
                        }
                    }
                    FfmpegEvent::Log(LogLevel::Error, msg) => {
                        tracing::error!("FFmpeg error: {}", msg);
                    }
                    _ => {}
                }
            });

        Ok(())
    }

    pub async fn extract_with_reencoding(
        &self,
        input: &Path,
        output: &Path,
        start: f64,
        duration: f64,
        width: u32,
        height: u32,
        bitrate: &str,
    ) -> Result<()> {
        let mut command = FfmpegCommand::new();

        if let Some(path) = &self.ffmpeg_path {
            command = command.path(path);
        }

        command
            .input(input)
            .args(&[
                "-ss", &start.to_string(),
                "-t", &duration.to_string(),
                "-c:v", "libx264",
                "-preset", "fast",
                "-crf", "23",
                "-vf", &format!("scale={}:{}", width, height),
                "-b:v", bitrate,
                "-c:a", "aac",
                "-b:a", "128k",
            ])
            .output(output)
            .spawn()?
            .iter()?
            .for_each(|_| {});

        Ok(())
    }
}
```

### 2.2 Clip Extraction (Week 2)

**File**: `src-tauri/src/video/clip_extractor.rs`

```rust
use crate::video::ffmpeg_wrapper::FFmpegWrapper;
use crate::storage::models::{Clip, ClipMetadata};
use anyhow::Result;
use std::path::PathBuf;
use tokio::sync::mpsc;

pub struct ClipExtractor {
    ffmpeg: FFmpegWrapper,
    output_dir: PathBuf,
}

impl ClipExtractor {
    pub fn new(output_dir: PathBuf) -> Self {
        Self {
            ffmpeg: FFmpegWrapper::new(),
            output_dir,
        }
    }

    pub async fn extract_clip(
        &self,
        clip: &Clip,
        progress_tx: Option<mpsc::Sender<f64>>,
    ) -> Result<PathBuf> {
        let input_path = PathBuf::from(&clip.segment_path);
        let output_filename = format!("clip_{}_{}.mp4", clip.game_id, clip.event_id);
        let output_path = self.output_dir.join(&output_filename);

        // Calculate start time relative to segment
        let segment_start = clip.segment_start_time;
        let event_time = clip.event_time;
        let relative_start = event_time - segment_start;

        // Extract with 5-second buffer before event
        let buffer_before = 5.0;
        let buffer_after = 10.0;
        let start_time = (relative_start - buffer_before).max(0.0);
        let duration = buffer_before + buffer_after;

        self.ffmpeg.extract_segment(
            &input_path,
            &output_path,
            start_time,
            duration,
            progress_tx,
        ).await?;

        Ok(output_path)
    }

    pub async fn extract_clip_with_formatting(
        &self,
        clip: &Clip,
        format: VideoFormat,
    ) -> Result<PathBuf> {
        let (width, height, bitrate) = match format {
            VideoFormat::Shorts => (1080, 1920, "5M"),  // 9:16 vertical
            VideoFormat::Landscape720 => (1280, 720, "4M"),
            VideoFormat::Landscape1080 => (1920, 1080, "8M"),
        };

        let input_path = PathBuf::from(&clip.segment_path);
        let output_filename = format!("clip_{}_{}_{:?}.mp4", clip.game_id, clip.event_id, format);
        let output_path = self.output_dir.join(&output_filename);

        let segment_start = clip.segment_start_time;
        let event_time = clip.event_time;
        let relative_start = (event_time - segment_start - 5.0).max(0.0);

        self.ffmpeg.extract_with_reencoding(
            &input_path,
            &output_path,
            relative_start,
            15.0,
            width,
            height,
            bitrate,
        ).await?;

        Ok(output_path)
    }
}

#[derive(Debug, Clone, Copy)]
pub enum VideoFormat {
    Shorts,           // 1080x1920 (9:16)
    Landscape720,     // 1280x720 (16:9)
    Landscape1080,    // 1920x1080 (16:9)
}
```

### 2.3 Thumbnail Generation (Week 2)

**File**: `src-tauri/src/video/thumbnail.rs`

```rust
use crate::video::ffmpeg_wrapper::FFmpegWrapper;
use anyhow::Result;
use std::path::{Path, PathBuf};

pub struct ThumbnailGenerator {
    ffmpeg: FFmpegWrapper,
    output_dir: PathBuf,
}

impl ThumbnailGenerator {
    pub fn new(output_dir: PathBuf) -> Self {
        Self {
            ffmpeg: FFmpegWrapper::new(),
            output_dir,
        }
    }

    pub async fn generate_thumbnail(
        &self,
        video_path: &Path,
        timestamp: f64,
        output_filename: &str,
    ) -> Result<PathBuf> {
        let output_path = self.output_dir.join(output_filename);

        let mut command = ffmpeg_sidecar::command::FfmpegCommand::new();

        command
            .input(video_path)
            .args(&[
                "-ss", &timestamp.to_string(),
                "-vframes", "1",
                "-vf", "scale=320:180",  // 16:9 thumbnail
                "-q:v", "2",  // High quality
            ])
            .output(&output_path)
            .spawn()?
            .iter()?
            .for_each(|_| {});

        Ok(output_path)
    }

    pub async fn generate_clip_thumbnail(&self, clip_id: i64, video_path: &Path) -> Result<PathBuf> {
        let filename = format!("clip_thumb_{}.jpg", clip_id);

        // Extract frame from 2 seconds into clip (after intro)
        self.generate_thumbnail(video_path, 2.0, &filename).await
    }

    pub async fn generate_compilation_thumbnail(&self, compilation_id: i64, video_path: &Path) -> Result<PathBuf> {
        let filename = format!("compilation_thumb_{}.jpg", compilation_id);

        // Extract frame from 1 second (after fade-in)
        self.generate_thumbnail(video_path, 1.0, &filename).await
    }
}
```

### 2.4 Multi-Clip Composition (Week 3-4)

**File**: `src-tauri/src/video/compositor.rs`

```rust
use crate::video::ffmpeg_wrapper::FFmpegWrapper;
use crate::storage::models::Clip;
use anyhow::Result;
use std::path::{Path, PathBuf};
use tokio::sync::mpsc;

#[derive(Debug, Clone)]
pub enum Transition {
    Cut,
    FadeBlack(f64),  // duration in seconds
    FadeWhite(f64),
    Dissolve(f64),
}

pub struct VideoCompositor {
    ffmpeg: FFmpegWrapper,
    output_dir: PathBuf,
}

impl VideoCompositor {
    pub fn new(output_dir: PathBuf) -> Self {
        Self {
            ffmpeg: FFmpegWrapper::new(),
            output_dir,
        }
    }

    pub async fn compose_clips(
        &self,
        clips: Vec<PathBuf>,
        transitions: Vec<Transition>,
        output_filename: &str,
        progress_tx: Option<mpsc::Sender<f64>>,
    ) -> Result<PathBuf> {
        let output_path = self.output_dir.join(output_filename);

        // Generate FFmpeg complex filter for transitions
        let filter_complex = self.generate_filter_complex(&clips, &transitions)?;

        let mut command = ffmpeg_sidecar::command::FfmpegCommand::new();

        // Add all input files
        for clip in &clips {
            command = command.input(clip);
        }

        command
            .args(&[
                "-filter_complex", &filter_complex,
                "-c:v", "libx264",
                "-preset", "fast",
                "-crf", "23",
                "-c:a", "aac",
                "-b:a", "128k",
            ])
            .output(&output_path)
            .spawn()?
            .iter()?
            .for_each(|event| {
                if let ffmpeg_sidecar::event::FfmpegEvent::Progress(p) = event {
                    if let Some(tx) = &progress_tx {
                        // Estimate progress based on total duration
                        let percent = (p.frame as f64 / 1800.0) * 100.0;  // Assume 60fps, 30s total
                        tx.try_send(percent.min(100.0)).ok();
                    }
                }
            });

        Ok(output_path)
    }

    fn generate_filter_complex(&self, clips: &[PathBuf], transitions: &[Transition]) -> Result<String> {
        let mut filter = String::new();

        // Normalize audio levels for all clips
        for i in 0..clips.len() {
            filter.push_str(&format!("[{}:a]loudnorm=I=-16:TP=-1.5:LRA=11[a{}];", i, i));
        }

        // Generate transition filters
        let mut current_video = format!("[0:v]");
        let mut current_audio = format!("[a0]");

        for (i, transition) in transitions.iter().enumerate() {
            let next_input = i + 1;
            let next_video = format!("[{}:v]", next_input);
            let next_audio = format!("[a{}]", next_input);
            let output_video = if i == transitions.len() - 1 {
                "[outv]".to_string()
            } else {
                format!("[v{}]", i)
            };
            let output_audio = if i == transitions.len() - 1 {
                "[outa]".to_string()
            } else {
                format!("[a{}out]", i)
            };

            match transition {
                Transition::Cut => {
                    // Simple concatenation
                    filter.push_str(&format!(
                        "{}{}concat=n=2:v=1:a=0{};{}{}concat=n=2:v=0:a=1{};",
                        current_video, next_video, output_video,
                        current_audio, next_audio, output_audio
                    ));
                }
                Transition::FadeBlack(duration) => {
                    filter.push_str(&format!(
                        "{}fade=t=out:st=0:d={}{}[fade1];{}fade=t=in:st=0:d={}{}[fade2];[fade1][fade2]concat{};",
                        current_video, duration, next_video, duration, output_video,
                        current_audio, next_audio, output_audio
                    ));
                }
                Transition::Dissolve(duration) => {
                    filter.push_str(&format!(
                        "{}{}xfade=transition=dissolve:duration={}:offset=0{};{}{}acrossfade=d={}{};",
                        current_video, next_video, duration, output_video,
                        current_audio, next_audio, duration, output_audio
                    ));
                }
                _ => {}
            }

            current_video = output_video;
            current_audio = output_audio;
        }

        filter.push_str(&format!("{}{}amix=inputs={}[outa]", current_video, current_audio, clips.len()));

        Ok(filter)
    }
}
```

### 2.5 Video Editor Backend (Week 5-6)

**File**: `src-tauri/src/video/editor_backend.rs`

```rust
use crate::storage::models::{Clip, Timeline, TimelineClip};
use crate::video::compositor::{VideoCompositor, Transition};
use anyhow::Result;
use std::path::PathBuf;
use tokio::sync::mpsc;

pub struct VideoEditorBackend {
    compositor: VideoCompositor,
}

impl VideoEditorBackend {
    pub fn new(output_dir: PathBuf) -> Self {
        Self {
            compositor: VideoCompositor::new(output_dir),
        }
    }

    pub async fn render_timeline(
        &self,
        timeline: &Timeline,
        output_filename: &str,
        progress_tx: Option<mpsc::Sender<f64>>,
    ) -> Result<PathBuf> {
        // Load all clips in timeline order
        let clip_paths: Vec<PathBuf> = timeline.clips
            .iter()
            .map(|tc| PathBuf::from(&tc.clip_path))
            .collect();

        // Generate transitions
        let transitions: Vec<Transition> = timeline.clips
            .windows(2)
            .map(|pair| {
                let transition_type = pair[0].transition_type.as_deref().unwrap_or("cut");
                match transition_type {
                    "fade_black" => Transition::FadeBlack(0.5),
                    "fade_white" => Transition::FadeWhite(0.5),
                    "dissolve" => Transition::Dissolve(0.5),
                    _ => Transition::Cut,
                }
            })
            .collect();

        self.compositor.compose_clips(
            clip_paths,
            transitions,
            output_filename,
            progress_tx,
        ).await
    }

    pub async fn apply_effects(
        &self,
        clip_path: &PathBuf,
        effects: Vec<VideoEffect>,
        output_path: &PathBuf,
    ) -> Result<()> {
        // TODO: Implement effect application (Wave 4)
        Ok(())
    }
}

#[derive(Debug, Clone)]
pub enum VideoEffect {
    ColorGrade { brightness: f64, contrast: f64, saturation: f64 },
    SlowMotion { speed: f64 },
    Zoom { scale: f64, x: f64, y: f64 },
    Overlay { text: String, position: (u32, u32) },
}
```

### Wave 2 Validation Checklist

‚úÖ **Clip Extraction**:
- [ ] Single clip extracted from segment with correct timing
- [ ] 5-second buffer before event works correctly
- [ ] 10-second buffer after event captured
- [ ] Export in 9:16 (shorts) format
- [ ] Export in 16:9 (landscape) format
- [ ] Progress tracking works during extraction

‚úÖ **Thumbnail Generation**:
- [ ] Clip thumbnails generated at 2s timestamp
- [ ] Thumbnail resolution correct (320x180)
- [ ] Compilation thumbnails generated

‚úÖ **Multi-Clip Composition**:
- [ ] 3+ clips composed into single video
- [ ] Transitions work (cut, fade, dissolve)
- [ ] Audio normalized across clips
- [ ] No audio/video desync
- [ ] Progress tracking accurate

‚úÖ **Editor Backend**:
- [ ] Timeline data structure persisted
- [ ] Render timeline produces correct output
- [ ] Effects can be applied (basic)

---

## ü§ñ Wave 3: Auto-Composition & AI Features (5 weeks)

### Overview
**Goal**: AI-powered automatic video editing, music synchronization, template system, clip quality scoring

**Critical Dependencies**:
- `onnxruntime` for ML inference
- Music library integration
- Beat detection algorithm
- Clip metadata for ML features

### 3.1 Composition Engine (Week 1)

**File**: `src-tauri/Cargo.toml` (add dependencies)

```toml
[dependencies]
symphonia = "0.5"  # Audio decoding
aubio-rs = "0.2"   # Beat detection
```

**File**: `src-tauri/src/video/composition_engine.rs`

```rust
use crate::storage::models::Clip;
use crate::video::beat_detector::BeatDetector;
use anyhow::Result;

pub struct CompositionEngine {
    beat_detector: BeatDetector,
}

impl CompositionEngine {
    pub fn new() -> Self {
        Self {
            beat_detector: BeatDetector::new(),
        }
    }

    pub async fn auto_compose(
        &self,
        clips: Vec<Clip>,
        music_path: Option<String>,
        style: CompositionStyle,
    ) -> Result<Timeline> {
        // Sort clips by priority and timing
        let mut sorted_clips = clips.clone();
        sorted_clips.sort_by(|a, b| b.priority.cmp(&a.priority));

        // Detect beats if music provided
        let beats = if let Some(music) = &music_path {
            self.beat_detector.detect_beats(music).await?
        } else {
            vec![]
        };

        // Generate timeline based on style
        let timeline = match style {
            CompositionStyle::Fast => self.compose_fast(&sorted_clips, &beats).await?,
            CompositionStyle::Balanced => self.compose_balanced(&sorted_clips, &beats).await?,
            CompositionStyle::Cinematic => self.compose_cinematic(&sorted_clips, &beats).await?,
        };

        Ok(timeline)
    }

    async fn compose_fast(&self, clips: &[Clip], beats: &[f64]) -> Result<Timeline> {
        // Fast-paced: 2-3 second clips, cut on beat
        let mut timeline_clips = vec![];

        for (i, clip) in clips.iter().take(10).enumerate() {
            let trim_start = 3.0;  // Skip first 3 seconds (setup)
            let trim_duration = 2.5;  // Short, punchy clips

            timeline_clips.push(TimelineClip {
                clip_id: clip.id,
                clip_path: clip.file_path.clone(),
                trim_start,
                trim_duration,
                transition_type: Some("cut".to_string()),
                position: i as f64 * trim_duration,
            });
        }

        Ok(Timeline {
            id: 0,
            name: "Auto-Composed (Fast)".to_string(),
            clips: timeline_clips,
            duration: clips.len() as f64 * 2.5,
            created_at: chrono::Utc::now().timestamp(),
        })
    }

    async fn compose_balanced(&self, clips: &[Clip], beats: &[f64]) -> Result<Timeline> {
        // Balanced: Mix of clip lengths, varied transitions
        let mut timeline_clips = vec![];
        let mut position = 0.0;

        for (i, clip) in clips.iter().take(8).enumerate() {
            let trim_duration = match clip.priority {
                5 => 8.0,   // Pentakill: longer duration
                4 => 6.0,   // Quadrakill/Baron
                3 => 5.0,   // Triplekill
                _ => 4.0,   // Others
            };

            let transition = if i % 2 == 0 { "dissolve" } else { "cut" };

            timeline_clips.push(TimelineClip {
                clip_id: clip.id,
                clip_path: clip.file_path.clone(),
                trim_start: 2.0,
                trim_duration,
                transition_type: Some(transition.to_string()),
                position,
            });

            position += trim_duration;
        }

        Ok(Timeline {
            id: 0,
            name: "Auto-Composed (Balanced)".to_string(),
            clips: timeline_clips,
            duration: position,
            created_at: chrono::Utc::now().timestamp(),
        })
    }

    async fn compose_cinematic(&self, clips: &[Clip], beats: &[f64]) -> Result<Timeline> {
        // Cinematic: Longer clips, smooth transitions, music sync
        let mut timeline_clips = vec![];
        let mut position = 0.0;

        for (i, clip) in clips.iter().take(6).enumerate() {
            let trim_duration = match clip.priority {
                5 => 12.0,
                4 => 10.0,
                _ => 8.0,
            };

            timeline_clips.push(TimelineClip {
                clip_id: clip.id,
                clip_path: clip.file_path.clone(),
                trim_start: 1.0,
                trim_duration,
                transition_type: Some("dissolve".to_string()),
                position,
            });

            position += trim_duration;
        }

        Ok(Timeline {
            id: 0,
            name: "Auto-Composed (Cinematic)".to_string(),
            clips: timeline_clips,
            duration: position,
            created_at: chrono::Utc::now().timestamp(),
        })
    }
}

#[derive(Debug, Clone, Copy)]
pub enum CompositionStyle {
    Fast,
    Balanced,
    Cinematic,
}
```

### 3.2 Music Integration & Beat Detection (Week 2)

**File**: `src-tauri/src/video/beat_detector.rs`

```rust
use aubio::{Tempo, OnsetDetector};
use symphonia::core::codecs::{DecoderOptions};
use symphonia::core::formats::FormatOptions;
use symphonia::core::io::MediaSourceStream;
use symphonia::core::meta::MetadataOptions;
use symphonia::core::probe::Hint;
use anyhow::Result;
use std::path::Path;
use std::fs::File;

pub struct BeatDetector {
    sample_rate: u32,
}

impl BeatDetector {
    pub fn new() -> Self {
        Self {
            sample_rate: 44100,
        }
    }

    pub async fn detect_beats(&self, audio_path: &str) -> Result<Vec<f64>> {
        // Open audio file
        let file = File::open(audio_path)?;
        let mss = MediaSourceStream::new(Box::new(file), Default::default());

        // Create format reader
        let mut hint = Hint::new();
        hint.with_extension("mp3");

        let format_opts = FormatOptions::default();
        let metadata_opts = MetadataOptions::default();
        let decoder_opts = DecoderOptions::default();

        let probed = symphonia::default::get_probe()
            .format(&hint, mss, &format_opts, &metadata_opts)?;

        let mut format = probed.format;
        let track = format.tracks().first()
            .ok_or_else(|| anyhow::anyhow!("No audio track found"))?;

        // Decode audio samples
        let mut decoder = symphonia::default::get_codecs()
            .make(&track.codec_params, &decoder_opts)?;

        let mut beats = vec![];
        let mut tempo = Tempo::new(1024, 512, self.sample_rate)?;

        while let Ok(packet) = format.next_packet() {
            let decoded = decoder.decode(&packet)?;

            // Convert samples to f32 and feed to tempo detector
            let samples: Vec<f32> = decoded.spec().channels.iter()
                .flat_map(|ch| ch.samples())
                .map(|s| s.as_f32())
                .collect();

            for chunk in samples.chunks(512) {
                if tempo.do_result(chunk)? {
                    let beat_time = tempo.get_last_s();
                    beats.push(beat_time);
                }
            }
        }

        Ok(beats)
    }

    pub fn calculate_bpm(&self, beats: &[f64]) -> f64 {
        if beats.len() < 2 {
            return 120.0;  // Default BPM
        }

        // Calculate average time between beats
        let intervals: Vec<f64> = beats.windows(2)
            .map(|w| w[1] - w[0])
            .collect();

        let avg_interval = intervals.iter().sum::<f64>() / intervals.len() as f64;

        60.0 / avg_interval
    }
}
```

### 3.3 Template System (Week 3)

**File**: `src-tauri/src/video/templates.rs`

```rust
use serde::{Deserialize, Serialize};
use anyhow::Result;
use std::path::PathBuf;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoTemplate {
    pub id: String,
    pub name: String,
    pub description: String,
    pub style: CompositionStyle,
    pub max_clips: usize,
    pub aspect_ratio: AspectRatio,
    pub transitions: Vec<String>,
    pub effects: Vec<TemplateEffect>,
    pub music_category: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemplateEffect {
    pub effect_type: String,
    pub parameters: serde_json::Value,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum AspectRatio {
    Shorts,      // 9:16
    Landscape,   // 16:9
    Square,      // 1:1
}

pub struct TemplateManager {
    templates: Vec<VideoTemplate>,
}

impl TemplateManager {
    pub fn new() -> Self {
        let mut manager = Self {
            templates: vec![],
        };

        manager.load_default_templates();
        manager
    }

    fn load_default_templates(&mut self) {
        // "Best Plays" template
        self.templates.push(VideoTemplate {
            id: "best_plays".to_string(),
            name: "Best Plays".to_string(),
            description: "Top 5 plays with fast cuts".to_string(),
            style: CompositionStyle::Fast,
            max_clips: 5,
            aspect_ratio: AspectRatio::Shorts,
            transitions: vec!["cut".to_string()],
            effects: vec![],
            music_category: Some("electronic".to_string()),
        });

        // "Highlight Reel" template
        self.templates.push(VideoTemplate {
            id: "highlight_reel".to_string(),
            name: "Highlight Reel".to_string(),
            description: "Balanced compilation with transitions".to_string(),
            style: CompositionStyle::Balanced,
            max_clips: 8,
            aspect_ratio: AspectRatio::Landscape,
            transitions: vec!["dissolve".to_string(), "cut".to_string()],
            effects: vec![],
            music_category: Some("rock".to_string()),
        });

        // "Cinematic Montage" template
        self.templates.push(VideoTemplate {
            id: "cinematic_montage".to_string(),
            name: "Cinematic Montage".to_string(),
            description: "Epic slow-mo with smooth transitions".to_string(),
            style: CompositionStyle::Cinematic,
            max_clips: 6,
            aspect_ratio: AspectRatio::Landscape,
            transitions: vec!["dissolve".to_string()],
            effects: vec![
                TemplateEffect {
                    effect_type: "slow_motion".to_string(),
                    parameters: serde_json::json!({"speed": 0.5}),
                }
            ],
            music_category: Some("orchestral".to_string()),
        });
    }

    pub fn get_template(&self, id: &str) -> Option<&VideoTemplate> {
        self.templates.iter().find(|t| t.id == id)
    }

    pub fn list_templates(&self) -> &[VideoTemplate] {
        &self.templates
    }
}
```

### 3.4 AI Clip Quality Scorer (Week 4-5)

**File**: `src-tauri/Cargo.toml` (add dependency)

```toml
[dependencies]
onnxruntime = "0.0.14"
ndarray = "0.15"
```

**File**: `src-tauri/src/ai/clip_scorer.rs`

```rust
use onnxruntime::{environment::Environment, GraphOptimizationLevel, LoggingLevel};
use onnxruntime::session::Session;
use ndarray::{Array1, Array2};
use crate::storage::models::Clip;
use anyhow::Result;

pub struct ClipScorer {
    session: Session<'static>,
    environment: Environment,
}

impl ClipScorer {
    pub fn new(model_path: &str) -> Result<Self> {
        let environment = Environment::builder()
            .with_name("clip_scorer")
            .with_log_level(LoggingLevel::Warning)
            .build()?
            .into_arc();

        let session = Session::builder()?
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(4)?
            .with_model_from_file(model_path)?;

        Ok(Self {
            session,
            environment,
        })
    }

    pub fn score_clip(&self, clip: &Clip) -> Result<f32> {
        // Extract features from clip metadata
        let features = self.extract_features(clip);

        // Run inference
        let inputs = vec![features];
        let outputs = self.session.run(inputs)?;

        let score = outputs[0]
            .try_extract::<f32>()?
            .view()
            .to_owned()
            .into_dimensionality::<ndarray::Ix1>()?[0];

        Ok(score)
    }

    fn extract_features(&self, clip: &Clip) -> Array2<f32> {
        // Feature engineering for ML model
        let mut features = vec![
            // Event type features (one-hot encoding)
            if clip.event_type == "ChampionKill" { 1.0 } else { 0.0 },
            if clip.event_type == "MultiKill" { 1.0 } else { 0.0 },
            if clip.event_type == "BaronKill" { 1.0 } else { 0.0 },
            if clip.event_type == "DragonKill" { 1.0 } else { 0.0 },

            // Priority score (normalized)
            clip.priority as f32 / 5.0,

            // Kill count (normalized)
            clip.kill_count.unwrap_or(0) as f32 / 5.0,

            // Assist count (normalized)
            clip.assist_count.unwrap_or(0) as f32 / 10.0,

            // Game time (normalized, early/mid/late game)
            (clip.event_time / 60.0).min(40.0) / 40.0,

            // TODO: Add more features:
            // - Champion tier (meta strength)
            // - Player rank
            // - Match outcome (win/loss)
            // - Team gold advantage
        ];

        Array2::from_shape_vec((1, features.len()), features)
            .expect("Feature shape mismatch")
    }

    pub async fn batch_score_clips(&self, clips: &[Clip]) -> Result<Vec<(i64, f32)>> {
        let mut scores = vec![];

        for clip in clips {
            let score = self.score_clip(clip)?;
            scores.push((clip.id, score));
        }

        Ok(scores)
    }
}
```

### Wave 3 Validation Checklist

‚úÖ **Composition Engine**:
- [ ] Auto-compose generates valid timeline
- [ ] Fast style: 2-3s clips, cut transitions
- [ ] Balanced style: mix of lengths, varied transitions
- [ ] Cinematic style: longer clips, smooth transitions
- [ ] Clips sorted by priority correctly

‚úÖ **Music & Beat Detection**:
- [ ] Beat detection works on MP3 files
- [ ] BPM calculated accurately
- [ ] Clips synchronized to music beats
- [ ] Audio ducking on important moments

‚úÖ **Template System**:
- [ ] 3+ default templates available
- [ ] Template application generates correct output
- [ ] Custom templates can be saved
- [ ] Template effects applied correctly

‚úÖ **AI Clip Scorer**:
- [ ] ONNX model inference works
- [ ] Clip features extracted correctly
- [ ] Scores correlate with quality (manual validation)
- [ ] Batch scoring performant (<1s for 100 clips)

---

## üé® Wave 4: Professional Video Editor UI (4 weeks)

### Overview
**Goal**: Full-featured video editor with timeline, playback, effects, text overlays, export settings

### 4.1 Clip Gallery (Week 1)

**File**: `src/components/ClipGallery.tsx`

```typescript
import { useEffect, useState } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { Checkbox } from '@/components/ui/checkbox';

interface Clip {
  id: number;
  gameId: number;
  eventType: string;
  priority: number;
  filePath: string;
  thumbnailPath?: string;
  duration: number;
}

export function ClipGallery() {
  const [clips, setClips] = useState<Clip[]>([]);
  const [selectedClips, setSelectedClips] = useState<number[]>([]);
  const [filter, setFilter] = useState<'all' | 'high' | 'pentakills'>('all');

  useEffect(() => {
    loadClips();
  }, [filter]);

  const loadClips = async () => {
    const allClips = await invoke<Clip[]>('get_clips');

    let filtered = allClips;
    if (filter === 'high') {
      filtered = allClips.filter(c => c.priority >= 3);
    } else if (filter === 'pentakills') {
      filtered = allClips.filter(c => c.eventType === 'Pentakill');
    }

    setClips(filtered);
  };

  const toggleClipSelection = (clipId: number) => {
    setSelectedClips(prev =>
      prev.includes(clipId)
        ? prev.filter(id => id !== clipId)
        : [...prev, clipId]
    );
  };

  const addToTimeline = async () => {
    await invoke('add_clips_to_timeline', {
      clipIds: selectedClips,
    });
  };

  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between">
        <div className="flex gap-2">
          <Button
            variant={filter === 'all' ? 'default' : 'outline'}
            onClick={() => setFilter('all')}
          >
            All Clips
          </Button>
          <Button
            variant={filter === 'high' ? 'default' : 'outline'}
            onClick={() => setFilter('high')}
          >
            High Priority
          </Button>
          <Button
            variant={filter === 'pentakills' ? 'default' : 'outline'}
            onClick={() => setFilter('pentakills')}
          >
            Pentakills Only
          </Button>
        </div>

        <Button
          onClick={addToTimeline}
          disabled={selectedClips.length === 0}
        >
          Add {selectedClips.length} to Timeline
        </Button>
      </div>

      <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-4">
        {clips.map(clip => (
          <Card key={clip.id} className="relative">
            <CardHeader className="p-3">
              <Checkbox
                checked={selectedClips.includes(clip.id)}
                onCheckedChange={() => toggleClipSelection(clip.id)}
                className="absolute top-2 left-2 z-10"
              />
              <CardTitle className="text-sm flex items-center justify-between">
                <span>{clip.eventType}</span>
                <Badge variant={getPriorityVariant(clip.priority)}>
                  {clip.priority}‚≠ê
                </Badge>
              </CardTitle>
            </CardHeader>

            <CardContent className="p-3">
              <div className="aspect-video bg-muted rounded overflow-hidden">
                {clip.thumbnailPath ? (
                  <img
                    src={clip.thumbnailPath}
                    alt={clip.eventType}
                    className="w-full h-full object-cover"
                  />
                ) : (
                  <video
                    src={clip.filePath}
                    className="w-full h-full"
                    muted
                    loop
                    onMouseEnter={e => e.currentTarget.play()}
                    onMouseLeave={e => e.currentTarget.pause()}
                  />
                )}
              </div>
              <div className="mt-2 text-xs text-muted-foreground">
                {clip.duration.toFixed(1)}s
              </div>
            </CardContent>
          </Card>
        ))}
      </div>
    </div>
  );
}

function getPriorityVariant(priority: number): 'default' | 'secondary' | 'destructive' {
  if (priority >= 4) return 'destructive';
  if (priority >= 3) return 'default';
  return 'secondary';
}
```

### 4.2 Timeline Editor (Week 2)

**File**: `src/components/TimelineEditor.tsx`

```typescript
import { useEffect, useRef, useState } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { DndContext, DragEndEvent, closestCenter } from '@dnd-kit/core';
import { SortableContext, arrayMove, horizontalListSortingStrategy } from '@dnd-kit/sortable';
import { useSortable } from '@dnd-kit/sortable';
import { CSS } from '@dnd-kit/utilities';

interface TimelineClip {
  id: number;
  clipId: number;
  clipPath: string;
  thumbnailPath?: string;
  trimStart: number;
  trimDuration: number;
  position: number;
  transitionType?: string;
}

export function TimelineEditor() {
  const [timeline, setTimeline] = useState<TimelineClip[]>([]);
  const [currentTime, setCurrentTime] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const timelineRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    loadTimeline();
  }, []);

  const loadTimeline = async () => {
    const data = await invoke<TimelineClip[]>('get_timeline');
    setTimeline(data);
  };

  const handleDragEnd = (event: DragEndEvent) => {
    const { active, over } = event;

    if (over && active.id !== over.id) {
      setTimeline(items => {
        const oldIndex = items.findIndex(item => item.id === active.id);
        const newIndex = items.findIndex(item => item.id === over.id);

        return arrayMove(items, oldIndex, newIndex);
      });
    }
  };

  const removeClip = async (clipId: number) => {
    await invoke('remove_clip_from_timeline', { clipId });
    await loadTimeline();
  };

  const updateTransition = async (clipId: number, transition: string) => {
    await invoke('update_timeline_clip_transition', {
      clipId,
      transitionType: transition,
    });
    await loadTimeline();
  };

  return (
    <div className="flex flex-col h-full">
      {/* Playback Controls */}
      <div className="flex items-center gap-4 p-4 border-b">
        <Button
          onClick={() => setIsPlaying(!isPlaying)}
          variant="outline"
        >
          {isPlaying ? <PauseIcon /> : <PlayIcon />}
        </Button>

        <div className="flex-1">
          <Slider
            value={[currentTime]}
            max={timeline.reduce((acc, clip) => acc + clip.trimDuration, 0)}
            step={0.1}
            onValueChange={([value]) => setCurrentTime(value)}
          />
        </div>

        <div className="text-sm text-muted-foreground">
          {formatTime(currentTime)} / {formatTime(timeline.reduce((acc, clip) => acc + clip.trimDuration, 0))}
        </div>
      </div>

      {/* Timeline */}
      <div ref={timelineRef} className="flex-1 overflow-x-auto p-4">
        <DndContext collisionDetection={closestCenter} onDragEnd={handleDragEnd}>
          <SortableContext
            items={timeline.map(clip => clip.id)}
            strategy={horizontalListSortingStrategy}
          >
            <div className="flex gap-2">
              {timeline.map(clip => (
                <TimelineClipItem
                  key={clip.id}
                  clip={clip}
                  onRemove={() => removeClip(clip.id)}
                  onTransitionChange={transition => updateTransition(clip.id, transition)}
                />
              ))}
            </div>
          </SortableContext>
        </DndContext>
      </div>
    </div>
  );
}

function TimelineClipItem({ clip, onRemove, onTransitionChange }: {
  clip: TimelineClip;
  onRemove: () => void;
  onTransitionChange: (transition: string) => void;
}) {
  const {
    attributes,
    listeners,
    setNodeRef,
    transform,
    transition,
  } = useSortable({ id: clip.id });

  const style = {
    transform: CSS.Transform.toString(transform),
    transition,
  };

  return (
    <div
      ref={setNodeRef}
      style={style}
      {...attributes}
      {...listeners}
      className="relative w-40 h-24 bg-muted rounded overflow-hidden cursor-move"
    >
      {clip.thumbnailPath && (
        <img
          src={clip.thumbnailPath}
          alt="Clip"
          className="w-full h-full object-cover"
        />
      )}

      <div className="absolute inset-0 bg-gradient-to-t from-black/60 to-transparent" />

      <div className="absolute bottom-1 left-1 right-1 flex items-center justify-between text-xs text-white">
        <span>{clip.trimDuration.toFixed(1)}s</span>

        <DropdownMenu>
          <DropdownMenuTrigger asChild>
            <Button variant="ghost" size="icon" className="h-6 w-6">
              <MoreVertical className="h-3 w-3" />
            </Button>
          </DropdownMenuTrigger>
          <DropdownMenuContent>
            <DropdownMenuLabel>Transition</DropdownMenuLabel>
            <DropdownMenuItem onClick={() => onTransitionChange('cut')}>
              Cut
            </DropdownMenuItem>
            <DropdownMenuItem onClick={() => onTransitionChange('fade_black')}>
              Fade to Black
            </DropdownMenuItem>
            <DropdownMenuItem onClick={() => onTransitionChange('dissolve')}>
              Dissolve
            </DropdownMenuItem>
            <DropdownMenuSeparator />
            <DropdownMenuItem onClick={onRemove} className="text-destructive">
              Remove
            </DropdownMenuItem>
          </DropdownMenuContent>
        </DropdownMenu>
      </div>
    </div>
  );
}

function formatTime(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins}:${secs.toString().padStart(2, '0')}`;
}
```

### Wave 4 continues with:
- **Week 3**: Playback controls, effects panel
- **Week 4**: Text overlays, export settings, polish

**Validation Checklist**:
- [ ] Timeline drag-and-drop works smoothly
- [ ] Video playback synchronized
- [ ] Effects applied in real-time preview
- [ ] Text overlays customizable
- [ ] Export dialog with all format options

---

## üöÄ Wave 5: Deployment & Distribution (2 weeks)

### Overview
**Goal**: Production-ready installer, auto-update system, code signing, CI/CD pipeline

### 5.1 Tauri Updater Setup

**File**: `src-tauri/tauri.conf.json` (update)

```json
{
  "tauri": {
    "updater": {
      "active": true,
      "endpoints": [
        "https://releases.lolshorts.com/{{target}}/{{current_version}}"
      ],
      "dialog": true,
      "pubkey": "YOUR_PUBLIC_KEY_HERE"
    }
  }
}
```

**Backend**: `src-tauri/src/updater/mod.rs`

```rust
use tauri::Manager;

pub async fn check_for_updates(app: tauri::AppHandle) -> anyhow::Result<()> {
    let update_resp = app.updater().check().await?;

    if let Some(update) = update_resp.update() {
        tracing::info!("Update available: {}", update.version);

        update.download_and_install().await?;

        // Prompt user to restart
        app.emit_all("update-downloaded", ())?;
    }

    Ok(())
}
```

### 5.2 CI/CD Pipeline

**File**: `.github/workflows/release.yml`

```yaml
name: Release Build

on:
  push:
    tags:
      - 'v*'

jobs:
  build-windows:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 18

      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Install dependencies
        run: pnpm install

      - name: Build
        run: pnpm tauri build

      - name: Sign executable
        run: |
          signtool sign /f ${{ secrets.CODE_SIGNING_CERT }} \
            /p ${{ secrets.CODE_SIGNING_PASSWORD }} \
            src-tauri/target/release/lolshorts.exe

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            src-tauri/target/release/bundle/msi/*.msi
            src-tauri/target/release/bundle/nsis/*.exe
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### Wave 5 Validation Checklist

‚úÖ **Installer**:
- [ ] MSI installer works on clean Windows 10/11
- [ ] Desktop shortcut created
- [ ] Start menu entry created
- [ ] Uninstaller removes all files
- [ ] FFmpeg bundled correctly

‚úÖ **Auto-Update**:
- [ ] Update check runs on app start
- [ ] Update downloads in background
- [ ] Update installs on restart
- [ ] Signature verification works
- [ ] Rollback on failed update

‚úÖ **CI/CD**:
- [ ] Build triggered on tag push
- [ ] All tests pass before release
- [ ] Executable signed with EV cert
- [ ] Release uploaded to GitHub
- [ ] Update server notified

---

## üí∞ Cost Analysis

### Development Costs

| Item | Cost | Notes |
|------|------|-------|
| **Team Salaries (22 weeks)** | $52,800 | 2 developers √ó $1,200/week |
| **Supabase Pro** | $500 | $25/month √ó 20 months (dev + 1yr) |
| **Sentry Team** | $600 | $30/month √ó 20 months |
| **EV Code Signing Certificate** | $400 | 1-year certificate |
| **Design Assets** | $300 | Icons, logo, marketing |
| **Domain & Hosting** | $200 | 2 years prepaid |
| **Stripe Setup** | $0 | Free for standard account |
| **Music Licensing** | $300 | Royalty-free music packs |
| **Testing Devices** | $2,000 | 2√ó mid-range Windows PCs |
| **Software Licenses** | $0 | All open-source tools |
| **Legal** | $4,000 | Terms of Service, Privacy Policy, business setup |
| **Total** | **$61,100** | One-time investment |

### Monthly Ongoing Costs

| Item | Monthly Cost | Notes |
|------|--------------|-------|
| Supabase Pro | $25 | Database + Auth + Storage |
| Sentry Team | $30 | Error tracking + Performance monitoring |
| Update Server (GitHub Releases) | $0 | Free for public repos |
| Domain | $10 | .com domain |
| CDN (Cloudflare Pro) | $20 | Fast asset delivery |
| Email Service (SendGrid) | $15 | Transactional emails |
| Analytics (PostHog) | $0 | Free tier (10K events/month) |
| **Total** | **$1,151/month** | Ongoing operational cost |

### Revenue Model

**Pricing**:
- **FREE Tier**:
  - 720p export max
  - Watermark on videos
  - Max 5 clips per compilation
  - Basic templates only

- **PRO Tier**: $9.99/month
  - 1080p60 export
  - No watermark
  - Max 50 clips per compilation
  - All templates + AI features
  - Priority support

**Break-Even Analysis**:
- Monthly costs: $1,151
- Revenue per PRO user: $9.99
- Break-even: **150 PRO users**

**Revenue Projections** (Conservative):
| Month | Users | PRO Users (10%) | MRR | Costs | Profit |
|-------|-------|-----------------|-----|-------|--------|
| Month 1 | 100 | 10 | $100 | $1,151 | -$1,051 |
| Month 3 | 500 | 50 | $500 | $1,151 | -$651 |
| Month 6 | 2,000 | 200 | $2,000 | $1,151 | $849 |
| Month 12 | 5,000 | 500 | $5,000 | $1,151 | $3,849 |

**Break-even**: Month 5-6 (with 200 PRO users)

---

## ‚è±Ô∏è Timeline Analysis

### 2-Person Team (Recommended)
**Total Duration**: 22 weeks (5.5 months)

| Wave | Weeks | Calendar Dates |
|------|-------|----------------|
| Wave 1 | 5 weeks | Nov 5 - Dec 9 |
| Wave 2 | 6 weeks | Dec 10 - Jan 20 |
| Wave 3 | 5 weeks | Jan 21 - Feb 24 |
| Wave 4 | 4 weeks | Feb 25 - Mar 24 |
| Wave 5 | 2 weeks | Mar 25 - Apr 7 |
| **Total** | **22 weeks** | **Nov 5 - Apr 7** |

**Team Composition**:
- **Developer 1** (Backend): Rust, Tauri, video processing
- **Developer 2** (Full-stack): React, database, CI/CD

**Cost**: $52,800 (2 √ó $1,200/week √ó 22 weeks)

### Solo Development
**Total Duration**: 35 weeks (8.75 months)

| Wave | Weeks | Calendar Dates |
|------|-------|----------------|
| Wave 1 | 8 weeks | Nov 5 - Dec 30 |
| Wave 2 | 10 weeks | Dec 31 - Mar 9 |
| Wave 3 | 8 weeks | Mar 10 - May 4 |
| Wave 4 | 6 weeks | May 5 - Jun 15 |
| Wave 5 | 3 weeks | Jun 16 - Jul 6 |
| **Total** | **35 weeks** | **Nov 5 - Jul 6** |

**Cost**: $0 (sweat equity = $76,800 opportunity cost @ $2,200/week)

### 4-Person Team (Accelerated)
**Total Duration**: 14 weeks (3.5 months)

| Wave | Weeks | Calendar Dates |
|------|-------|----------------|
| Waves 1-2 (parallel) | 6 weeks | Nov 5 - Dec 16 |
| Waves 3-4 (parallel) | 5 weeks | Dec 17 - Jan 20 |
| Wave 5 | 2 weeks | Jan 21 - Feb 3 |
| Polish | 1 week | Feb 4 - Feb 10 |
| **Total** | **14 weeks** | **Nov 5 - Feb 10** |

**Team Composition**:
- Backend Engineer (Rust/Tauri)
- Full-stack Engineer (React/TypeScript)
- Video Engineer (FFmpeg/OpenCV)
- QA Engineer (Testing/Automation)

**Cost**: $100,800 (4 √ó $1,800/week √ó 14 weeks)

---

## üéØ Recommendation

### For Solo Developer (You)

**Best Option**: **2-Person Team** (22 weeks, $52,800)

**Reasoning**:
1. **Quality**: Two developers = code review, better architecture, fewer bugs
2. **Speed**: 13 weeks faster than solo (ship in April vs July)
3. **Expertise**: Cover both frontend and backend deeply
4. **Cost-Effective**: $52K is reasonable for 5.5 months of focused development
5. **Risk Mitigation**: Redundancy if one developer leaves

**Alternative**: Solo development if budget constrained
- Longer timeline (35 weeks) but $0 cash outlay
- Trade-off: 8.75 months vs 5.5 months
- Opportunity cost: $76K in sweat equity

**How to Fund**:
1. **Bootstrap**: Use savings ($52K + $20K buffer = $72K)
2. **Angel Investment**: Raise $100K for team + 6 months runway
3. **Pre-sales**: Sell PRO lifetime licenses ($199) to early adopters

**Next Steps**:
1. Decide on team size (solo vs 2-person)
2. Set start date (recommend: this week)
3. Create hiring plan (if 2-person)
4. Set up development infrastructure (Supabase, Sentry, GitHub)
5. Begin Wave 1 implementation

---

## üìã Validation Checklists

### Wave 1 Validation
- [ ] Supabase authentication works (sign up, sign in, refresh)
- [ ] License tiers enforced correctly (FREE vs PRO)
- [ ] Screenshot capture functional
- [ ] Enhanced event detection (pentakill, quadrakill, baron, etc.)
- [ ] All database migrations applied successfully
- [ ] Unit tests pass (>80% coverage)

### Wave 2 Validation
- [ ] Clip extraction from segments accurate
- [ ] Thumbnail generation fast (<2s per clip)
- [ ] Multi-clip composition works with transitions
- [ ] Audio normalization correct
- [ ] No audio/video desync
- [ ] Progress tracking functional
- [ ] Export formats working (9:16, 16:9, 1080p, 720p)

### Wave 3 Validation
- [ ] Auto-composition generates watchable videos
- [ ] Music beat detection accurate (¬±50ms)
- [ ] Template system functional (3+ templates)
- [ ] AI clip scorer produces reasonable scores
- [ ] Batch scoring performant (<1s for 100 clips)
- [ ] Composition styles work (Fast, Balanced, Cinematic)

### Wave 4 Validation
- [ ] Clip gallery loads quickly (<1s for 100 clips)
- [ ] Timeline editor drag-and-drop smooth
- [ ] Video playback synchronized
- [ ] Effects applied correctly
- [ ] Text overlays customizable
- [ ] Export dialog complete
- [ ] UI polished and responsive

### Wave 5 Validation
- [ ] Installer works on clean Windows systems
- [ ] Auto-update functional
- [ ] Code signing verified
- [ ] CI/CD pipeline successful
- [ ] Performance targets met (see below)
- [ ] All documentation complete

---

## üéØ Performance Targets

| Metric | Target | Validation Method |
|--------|--------|-------------------|
| App Startup | <3s cold start | Measure with `Instant::now()` |
| LCU Connection | <2s | Time from detect to connected |
| Event Detection Latency | <500ms | Poll ‚Üí Trigger ‚Üí Clip saved |
| Video Processing | <30s per minute | FFmpeg extraction + composition |
| Memory Usage (Idle) | <500MB | Task Manager monitoring |
| Memory Usage (Processing) | <2GB | During video composition |
| Disk Space (Install) | <300MB | Installer size + dependencies |
| Crash Rate | <0.1% | Sentry monitoring |
| User Rating | >4.5/5 | Beta feedback |

---

## üö® Risk Assessment

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| FFmpeg complexity | Medium | High | Use templates, presets, extensive testing |
| LCU API changes | Low | Medium | Abstraction layer, version detection |
| Performance issues | Medium | High | Hardware encoding, profiling, optimization |
| Memory leaks | Low | High | Automated leak detection, stress testing |
| Cross-platform bugs | Low | Low | Windows-only initially |

### Timeline Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Feature creep | High | High | Strict Wave boundaries, MVP-first |
| Underestimated complexity | Medium | Medium | Buffer time, cut features if needed |
| Dependency issues | Low | Medium | Pin versions, test on clean systems |
| Team availability | Medium | High | Hire contractors, document well |

### Business Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Low user adoption | Medium | High | Beta testing, marketing, community |
| Competing products | Medium | Medium | Unique features, superior UX |
| Riot TOS violation | Low | High | Follow guidelines, legal review |
| Piracy | Medium | Low | Online license validation |

---

## üìû Support & Contribution

### Reporting Issues
- GitHub Issues: Create detailed bug reports
- Include: version, OS, steps to reproduce, logs
- Check FAQ and existing issues first

### Contributing
- Read CONTRIBUTING.md for guidelines
- Follow code style (CLAUDE.md)
- Write tests for new features
- Submit PRs with clear descriptions

### Community
- Discord server: (TBD after launch)
- Twitter: @lolshorts (TBD)
- Reddit: r/lolshorts (TBD)

---

## üéâ Launch Strategy

### Beta Phase (Month 1)
- Invite 50-100 beta testers
- Gather feedback on core features
- Fix critical bugs
- Iterate on UX

### Public Launch (Month 2)
- Press release + marketing push
- Post on Reddit (r/leagueoflegends, r/leagueoflegendsmeta)
- YouTube creator partnerships
- Twitter campaign

### Growth (Month 3-12)
- Content marketing (tutorials, guides)
- SEO optimization
- Community building (Discord)
- Feature updates based on feedback

**Success Metrics**:
- 5,000 users by Month 6
- 500 PRO users (10% conversion)
- $5,000 MRR
- 4.5+ star rating

---

**Last Updated**: 2025-11-04
**Next Review**: After Wave 1 completion (2025-12-09)
**Status**: ‚úÖ Production roadmap complete - Ready to begin Wave 1 implementation
